---
title: "Sprawozdanie 1"
author: "Andrzej Miczek & Jakub Laszczyk"
date: "10.10.2023"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## **Przygotowanie zbioru danych** 

Wczytanie bibliotek, zamiana zmiennych kategorycznych, standaryzacja oraz bilansowanie danych.

```{r}
library(pROC)
library(caret)
dane <- read.csv("stroke.csv", sep=";")

# usuwanie brakow danych

sum(sapply(dane, function(x) sum(is.na(x))))
dane <-na.omit(dane)

# zamiana zmiennych kategorycznych 
# gender i evermarried na wartoÅ›ci zero-jednykowe 

dummy_data <- dummyVars(~ work_type, data = dane)
dummy_data_transformed <- as.data.frame(predict(dummy_data, newdata = dane))
dane1 <- cbind(dane, dummy_data_transformed)

dummy_data <- dummyVars(~ Residence_type, data = dane1)
dummy_data_transformed <- as.data.frame(predict(dummy_data, newdata = dane1))
dane1 <- cbind(dane1, dummy_data_transformed)

dummy_data <- dummyVars(~ smoking_status, data = dane1)
dummy_data_transformed <- as.data.frame(predict(dummy_data, newdata = dane1))
dane1 <- cbind(dane1, dummy_data_transformed)

dane1$gender <- ifelse(dane1$gender == "Male", 1, 0)
dane1$ever_married <- ifelse(dane1$ever_married == "Yes", 1, 0)
dane1$Stroke <- dane1$stroke

dane1 <- dane1[,-c(6,7,10,11)]
str(dane1)
table(dane1$Stroke)
dane1$Stroke <- factor(dane1$Stroke,levels = c("0", "1"), labels = c("nie", "tak"))
str(dane1)

# bilansowanie danych 
dane1 <- dane1[1:1000,] 

# standaryzacja danych
scaled_data <- as.data.frame(scale(dane1[,-19]))
scaled_data$Stroke <- dane1$Stroke
```

PodziaÅ‚ na zbior testowy i treningowy.

```{r}
# bez standaryzacji

set.seed(123)
ind <- sample(2, nrow(dane1), replace = TRUE, prob = c(0.7, 0.3))
train_set <- dane1[ind==1,]
test_set <- dane1[ind==2,]
# ze standaryzacja

set.seed(123)
ind <- sample(2, nrow(scaled_data), replace = TRUE, prob = c(0.7, 0.3))
train_set2 <- scaled_data[ind==1,]
test_set2 <- scaled_data[ind==2,]
```

## **Zadanie 1. Pytania wstÄ™pne** 

**1. W jakim celu dokonuje siÄ™ podziaÅ‚u zbioru danych na zbiÃ³r uczÄ…cy i testowy? W jaki sposÃ³b ten podziaÅ‚ powinien zostaÄ‡ wykonany?**

PodziaÅ‚u na zbiÃ³r treningowy i testowy dokonuje siÄ™ w celu trenowania i testowania modelu. Model trenuje siÄ™ na zbiorze treningowym, w tym etapie dopasowywuje siÄ™ wartoÅ›ci hiperparametrÃ³w, naleÅ¼y zwrÃ³ciÄ‡ uwagÄ™ na to aby model nie byÅ‚ zbyt dopasowany do danych treningowych co moÅ¼e prowadziÄ‡ do mniejszej zdolnoÅ›ci do generalizacji oraz sÅ‚abszej predykcji na zbiorze testowym. Odpowiednio wytrenowany model sprawdza siÄ™ na zbiorze testowym ktÃ³ry nie byÅ‚ wczeÅ›niej znany dla naszego modelu. Nie ma okreÅ›lonego sposobu na dokonywanie podziaÅ‚u na zbiÃ³r testowy i treningowy, najczÄ™Å›ciej dokonuje siÄ™ go w proporcjach 70:30 lub 80:20.

**2. Czym jest macierz bÅ‚Ä™du?**

Macierz pomyÅ‚ek utworzona jest  poprzez zestawienie klasy prognozowanej i klasy faktycznie zaobserwowanej w wyniku czego powstajÄ… 4 przypadki:

* True-Positive (TP - prawdziwie pozytywne) to przypadki, gdy model przewiduje 
pozytywnÄ… klasÄ™, a w rzeczywistoÅ›ci zostaÅ‚a ona zaobserwowana jako pozytywna.
* True-Negative (TN â€“ prawdziwie negatywna) to przypadki, gdy model 
przewiduje negatywnÄ… klasÄ™, a w rzeczywistoÅ›ci zostaÅ‚a ona zaobserwowana jako 
negatywna.
* False-Positive (FP â€“ faÅ‚szywie pozytywna) to przypadki, gdy model przewiduje 
pozytywnÄ… klasÄ™, a w rzeczywistoÅ›ci zostaÅ‚a ona zaobserwowana jako negatywna.
* False-Negative (FN â€“ faÅ‚szywie negatywna) to przypadki, gdy model przewiduje 
negatywnÄ… klasÄ™, a w rzeczywistoÅ›ci zostaÅ‚a ona zaobserwowana jako 
pozytywna.


**3. Jaka jest rÃ³Å¼nica miÄ™dzy dokÅ‚adnoÅ›ciÄ…, czuÅ‚oÅ›ciÄ… a specyficznoÅ›ciÄ…? KtÃ³ra z tych miar i w jakim przypadku jest waÅ¼niejsza. PodaÄ‡ przykÅ‚ady.**

Na podstawie macierzy pomyÅ‚ek moÅ¼na utworzyÄ‡ cztery miary jakoÅ›ci 
klasyfikacji:

* **CzuÅ‚oÅ›Ä‡** (ang. sensitivity, recall) okreÅ›lana rÃ³wnieÅ¼ jako odsetek prawdziwie
pozytywnych (ang. true positive rate, TPR) â€“ mierzy skutecznoÅ›Ä‡ modelu 
w przewidywaniu rzeczywiÅ›cie pozytywnych przypadkÃ³w spoÅ›rÃ³d wszystkich 
zaobserwowanych pozytywnych przypadkÃ³w 
ð‘‡ð‘ƒð‘… =ð‘‡ð‘ƒ/ð‘ƒ=ð‘‡ð‘ƒ/(ð‘‡ð‘ƒ+ð¹ð‘)
 
* **SpecyficznoÅ›Ä‡** (ang. specificity, SPC) okreÅ›lana rÃ³wnieÅ¼ jako odsetek prawdziwie
negatywnych (ang. true negative rate, TNR) - mierzy skutecznoÅ›Ä‡ modelu 
w przewidywaniu rzeczywiÅ›cie negatywnych przypadkÃ³w spoÅ›rÃ³d wszystkich 
zaobserwowanych negatywnych przypadkÃ³w
ð‘‡ð‘ð‘… = ð‘‡ð‘/ð‘=ð‘‡ð‘/(ð¹ð‘ƒ+ð‘‡ð‘)

* **DokÅ‚adnoÅ›Ä‡** (ang. accuracy, ACC) - mierzy ona skutecznoÅ›Ä‡ modelu 
w identyfikowaniu prawdziwych negatywnych wynikÃ³w spoÅ›rÃ³d wszystkich 
przewidywanych jako negatywne.
ð´ð¶ð¶ =(ð‘‡ð‘ƒ+ð‘‡ð‘)/(ð‘ƒ+ð‘)

W zaleÅ¼noÅ›ci od badanego problemu rÃ³Å¼ne miary mogÄ… byÄ‡ najwaÅ¼niejsze, np jeÅ¼eli chcemy przewidzieÄ‡ chorobÄ™ serca najwaÅ¼niejszÄ… miarÄ… powinna byÄ‡ czuÅ‚oÅ›Ä‡ dlatego, Å¼e priorytetem jest minimalizacja faÅ‚szywych negatywnych wynikÃ³w. Oznacza to, Å¼e zaleÅ¼y nam na tym, aby jak najmniej przypadkÃ³w rzeczywistych chorÃ³b serca zostaÅ‚o pominiÄ™tych przez model. DokÅ‚adnoÅ›Ä‡ moÅ¼e byÄ‡ najwaÅ¼niejsza w sytuacji kiedy liczy siÄ™ dla nas jak najwiÄ™ksza liczba poprawnie sklasyfikowanych przypadkÃ³w oraz koszty obu bÅ‚Ä™dÃ³w sÄ… do siebie zbliÅ¼one, np w przypadku klasyfikacji typu produktÃ³w w sklepie. MoÅ¼e byÄ‡ ona tez mylÄ…ca w przypadku niezbilansowanego zbioru danych poniewaz jezeli mamy w zbiorze np 80% pozytywnych przypadkÃ³w, a 20% negatywnych to dokÅ‚adnoÅ›Ä‡ 80% wcale nie sugeruje Å¼e nasz model dobrze klasyfikuje nowe przypadki, moÅ¼e on rÃ³wnie dobrze klasyfikowaÄ‡ wszystkie przypadki jako pozytywne. Na specyficznoÅ›Ä‡ zwracamy uwagÄ™ jeÅ¼eli jest wysoki koszt przypadkÃ³w faÅ‚szywie negatywnych, np w badaniach antydopingowych kiedy faÅ‚szywie pozytywny wynik moÅ¼e zniszczyÄ‡ karierÄ™ sportowca.  


## **Zadanie 2. Metoda KNN** 

**1. Jak dziaÅ‚a metoda k-najbliÅ¼szych sÄ…siadÃ³w?**

Metoda k-najbliÅ¼szych sÄ…siadÃ³w (k-NN, od ang. k-Nearest Neighbors) to prosty i intuicyjny algorytm uÅ¼ywany do klasyfikacji i regresji. Algorytm ten opiera siÄ™ na zaÅ‚oÅ¼eniu, Å¼e podobne dane znajdujÄ… siÄ™ blisko siebie w przestrzeni cech. DziaÅ‚a on nastÄ™pujÄ…co: W pierwszym kroku algorytmu, dla kaÅ¼dego punktu w zbiorze treningowym, obliczane sÄ… odlegÅ‚oÅ›ci miÄ™dzy tym punktem a wszystkimi innymi punktami w zbiorze treningowym. NajczÄ™Å›ciej uÅ¼ywa siÄ™ miary odlegÅ‚oÅ›ci euklidesowej, choÄ‡ moÅ¼na stosowaÄ‡ inne miary odlegÅ‚oÅ›ci w zaleÅ¼noÅ›ci od rodzaju danych i problemu. Algorytm k-NN wymaga okreÅ›lenia parametru k, ktÃ³ry okreÅ›la liczbÄ™ najbliÅ¼szych sÄ…siadÃ³w branych pod uwagÄ™ przy klasyfikacji lub regresji. WybÃ³r k jest waÅ¼ny, poniewaÅ¼ wpÅ‚ywa na wydajnoÅ›Ä‡ i dokÅ‚adnoÅ›Ä‡ algorytmu. 
Aby dokonaÄ‡ klasyfikacji, dla nowego punktu, ktÃ³ry chcemy sklasyfikowaÄ‡, algorytm identyfikuje k najbliÅ¼szych sÄ…siadÃ³w tego punktu na podstawie obliczonych odlegÅ‚oÅ›ci. NastÄ™pnie zlicza, ile z tych sÄ…siadÃ³w naleÅ¼y do kaÅ¼dej klasy. Klasa, ktÃ³ra ma najwiÄ™kszÄ… liczbÄ™ sÄ…siadÃ³w, zostaje przypisana nowemu punktowi.

**2. Czym jest k w metodzie KNN? Jak dobraÄ‡ odpowiedniÄ… wartoÅ›Ä‡ k?**

W metodzie KNN, "k" oznacza liczbÄ™ najbliÅ¼szych sÄ…siadÃ³w, ktÃ³rzy sÄ… brani pod uwagÄ™ przy dokonywaniu klasyfikacji lub regresji dla nowego punktu danych. Jest to jeden z najwaÅ¼niejszych hiperparametrÃ³w w algorytmie KNN, a jego wybÃ³r ma istotny wpÅ‚yw na wyniki modelu. MoÅ¼na przedstawiÄ‡ kilka czynnikÃ³w, ktÃ³re warto wziÄ…Ä‡ pod uwagÄ™ przy doborze odpowiedniej wartoÅ›ci "k":

**Liczba sÄ…siadÃ³w w stosunku do liczby danych**: W ogÃ³lnoÅ›ci, im wiÄ™kszy zbiÃ³r danych, tym wiÄ™ksza liczba sÄ…siadÃ³w "k" jest odpowiednia. Dla maÅ‚ych zbiorÃ³w danych, maÅ‚a wartoÅ›Ä‡ "k" moÅ¼e dziaÅ‚aÄ‡ dobrze, podczas gdy dla duÅ¼ych zbiorÃ³w danych potrzeba wiÄ™kszej liczby sÄ…siadÃ³w, aby uzyskaÄ‡ stabilne wyniki.

**Charakterystyka danych**: Warto zwrÃ³ciÄ‡ uwagÄ™ na rozkÅ‚ad danych i ich strukturÄ™. JeÅ›li dane sÄ… gÄ™sto zagÄ™szczone w przestrzeni cech, mniejsza wartoÅ›Ä‡ "k" moÅ¼e byÄ‡ wystarczajÄ…ca do dokÅ‚adnej klasyfikacji lub regresji. W przypadku rozproszonych danych wiÄ™ksza wartoÅ›Ä‡ "k" moÅ¼e byÄ‡ bardziej odpowiednia.

**Overfitting vs. underfitting**: MaÅ‚a wartoÅ›Ä‡ "k" (np. 1 lub 2) moÅ¼e prowadziÄ‡ do nadmiernego dopasowania (overfitting), gdzie model staje siÄ™ zbyt wraÅ¼liwy na szum w danych i moÅ¼e Åºle generalizowaÄ‡. DuÅ¼a wartoÅ›Ä‡ "k" moÅ¼e prowadziÄ‡ do niedopasowania (underfitting), gdzie model jest zbyt uproszczony i nie jest w stanie uchwyciÄ‡ istotnych wzorcÃ³w w danych. WaÅ¼ne jest znalezienie zrÃ³wnowaÅ¼onej wartoÅ›ci "k", ktÃ³ra minimalizuje bÅ‚Ä…d generalizacji.

**Analiza krzywej walidacyjnej**: Przydatnym narzÄ™dziem do doboru odpowiedniej wartoÅ›ci "k" jest analiza krzywej walidacyjnej (validation curve). MoÅ¼esz przetestowaÄ‡ rÃ³Å¼ne wartoÅ›ci "k" i monitorowaÄ‡ wydajnoÅ›Ä‡ modelu na zbiorze walidacyjnym. Na podstawie tych wynikÃ³w moÅ¼esz wybraÄ‡ optymalnÄ… wartoÅ›Ä‡ "k".

**ReguÅ‚a pierwiastka z liczby danych**: Jednym z prostych podejÅ›Ä‡ jest wybÃ³r wartoÅ›ci "k" jako pierwiastka kwadratowego z liczby danych. JednakÅ¼e jest to tylko ogÃ³lna wskazÃ³wka, a ostateczny wybÃ³r zaleÅ¼y od charakterystyki problemu.

**Eksperymentowanie**: Ostateczny wybÃ³r wartoÅ›ci "k" moÅ¼e wymagaÄ‡ eksperymentowania i przetestowania rÃ³Å¼nych wartoÅ›ci. WaÅ¼ne jest, aby przeprowadziÄ‡ odpowiednie eksperymenty i oceniÄ‡ wydajnoÅ›Ä‡ modelu na zbiorze walidacyjnym.

PodsumowujÄ…c, wybÃ³r odpowiedniej wartoÅ›ci "k" w metodzie k-NN jest problemem hiperparametrycznym i zaleÅ¼y od konkretnego problemu oraz charakterystyki danych. Dobre dostosowanie wartoÅ›ci "k" jest kluczowe dla uzyskania dobrych wynikÃ³w modelu KNN, dlatego warto poÅ›wiÄ™ciÄ‡ czas na eksperymenty i analizÄ™.


**3. Czy k powinno byÄ‡ liczbÄ… parzystÄ…, nieparzystÄ…, czy nie ma to znaczenia? OdpowiedÅº uzasadniÄ‡ przeprowadzajÄ…c odpowiedniÄ… symulacjÄ™.**

W poniÅ¼szym kodzie zostaly sprawdzone wartosci k z przedziaÅ‚u od 1 do 15, widzimy ze w naszym przypadku wraz ze wzroste k zwieksza sie roc i sensitivity, a zmniejsza sie specyficity. Na podstawie naszego przypadku moÅ¼emy wysunÄ…Ä‡ wniosek, Å¼e nie ma znaczenia, czy liczba k jest akurat liczbÄ… parzystÄ… lub liczbÄ… nieparzysta, co jest uzasadnione sutyacjÄ… gdy przy zwiÄ™kszeniu wartoÅ›ci k zwiÄ™kszajÄ… siÄ™ rozpatrywane wartoÅ›ci wynikÃ³w.

```{r}
# KNN
trControl <- trainControl(method = "repeatedcv", 
                          number = 10,  
                          repeats = 3,  
                          classProbs = TRUE,
                          summaryFunction = twoClassSummary) 
set.seed(1234)
fit <- train(Stroke ~ ., 
             data = train_set,
             tuneGrid   = expand.grid(k = 1:15),
             method = "knn",
             tuneLength = 20,
             metric     = "ROC", 
             trControl = trControl,
             preProc = c("center", "scale"))  


fit
plot(fit)
varImp(fit)

pred <- predict(fit, newdata = test_set )
confusionMatrix(pred, test_set$Stroke, positive = 'tak' )
```


**4. Czy standaryzacja danych jest wymagana w przypadku wykorzystywania metody k-najbliÅ¼szych sÄ…siadÃ³w? Dlaczego tak/nie? ZastosowaÄ‡ metodÄ™ KNN na danych bez standaryzacji i ze standaryzacjÄ…. PorÃ³wnaÄ‡ uzyskane wyniki.**

Standaryzacja danych moÅ¼e mieÄ‡ wpÅ‚yw na wydajnoÅ›Ä‡ algorytmu k-NN, ale nie jest zawsze wymagana. Decyzja o standaryzacji zaleÅ¼y od charakterystyki danych i miary odlegÅ‚oÅ›ci uÅ¼ywanej w algorytmie KNN jednak poniewaÅ¼ KNN opiera siÄ™ na obliczaniu odlegÅ‚oÅ›ci miÄ™dzy punktami, waÅ¼ne jest, aby nasze funkcje uÅ¼ywaÅ‚y spÃ³jnej skali. W przeciwnym razie te o mniejszej skali bÄ™dÄ… dominowaÄ‡, a te o wiÄ™kszej skali nie bÄ™dÄ… miaÅ‚y prawie Å¼adnego wpÅ‚ywu. 

```{r}
# K-NN
trControl <- trainControl(method = "repeatedcv", 
                          number = 10,  
                          repeats = 3,  
                          classProbs = TRUE,
                          summaryFunction = twoClassSummary)  
set.seed(1234)
fit <- train(Stroke ~ ., 
             data = train_set2,
             tuneGrid   = expand.grid(k = 1:15),
             method = "knn",
             tuneLength = 20,
             metric     = "ROC", 
             trControl = trControl,
             preProc = c("center", "scale"))  

fit
plot(fit)
varImp(fit)

pred <- predict(fit, newdata = test_set2 )
confusionMatrix(pred, test_set2$Stroke, positive = 'tak' )
```

W naszym przypadku algorytm oparty na danych zestandaryzowanych daÅ‚ takie same wyniki jak w przypadku danych niepoddanych standaryzacji.


**5. W jaki sposÃ³b metoda KNN moÅ¼e zostaÄ‡ wykorzystana do rozwiÄ…zania problemu regresji?**

Metoda KNN moÅ¼e byÄ‡ wykorzystana do rozwiÄ…zania problemu regresji. Aby przeksztaÅ‚ciÄ‡ KNN na algorytm regresji, moÅ¼na zastosowaÄ‡ prostÄ… modyfikacjÄ™. Zamiast przewidywaÄ‡ klasÄ™, metoda k-NN bÄ™dzie przewidywaÄ‡ numerycznÄ… wartoÅ›Ä‡ lub zmiennÄ… ciÄ…gÅ‚Ä….:Aby przewidzieÄ‡ wartoÅ›Ä‡ regresji dla nowego punktu, moÅ¼na obliczyÄ‡ Å›redniÄ… (lub waÅ¼onÄ… Å›redniÄ…) wartoÅ›Ä‡ docelowÄ… dla k najbliÅ¼szych sÄ…siadÃ³w. Innym podejÅ›ciem jest wybÃ³r mediany lub innej statystyki opisowej jako przewidywanej wartoÅ›ci regresji.

**6. Czy wielkoÅ›Ä‡ zbioru danych ma znaczenie w przypadku tej metody? SprawdziÄ‡, czy liczba obserwacji wpÅ‚ywa na uzyskiwane wyniki.**

PoniewaÅ¼ w dane byÅ‚y Åºle zbilansowane zdecydowalismy sie juz na poczatku na zmniejszenie ilosci obserwacji tak aby otrzymywane wyniki byÅ‚y interpretowalne. MoÅ¼emy na tej podstawie wysunÄ…Ä‡ wniosek, Å¼e liczba obserwacji moÅ¼e mieÄ‡ wpÅ‚yw na uzyskiwane wyniki. W naszym przypadku zwiÄ™kszenie iloÅ›ci obserwacji powoduje, Å¼e predykcja jest bardzo, a wrÄ™cz caÅ‚kowicie niepoprawna. Trzeba przy tym zaznaczyÄ‡, Å¼e wiÄ™ksze znaczenie ma zbalansowanie danych. WiÄ™ksza liczba obserwacji odpowiednio zbalansowanych powinna daÄ‡ lepsze wyniki, lecz trzeba mieÄ‡ na uwadze, Å¼e zbyt duÅ¼a iloÅ›Ä‡ moÅ¼e skomplikowaÄ‡ obliczenia.

```{r}
# KNN
trControl <- trainControl(method = "repeatedcv", 
                          number = 10,  
                          repeats = 3,  
                          classProbs = TRUE,
                          summaryFunction = twoClassSummary)  
set.seed(1234)
fit <- train(Stroke ~ ., 
             data = train_set2,
             tuneGrid   = expand.grid(k = 1:15),
             method = "knn",
             tuneLength = 20,
             metric     = "ROC", 
             trControl = trControl,
             preProc = c("center", "scale"))  

fit
plot(fit)
varImp(fit)

pred <- predict(fit, newdata = test_set2 )
confusionMatrix(pred, test_set2$Stroke, positive = 'tak' )
```


**7. Czy w metodzie tej moÅ¼na wykorzystaÄ‡ i jeÅ›li tak, to w jaki sposÃ³b zmienne kategoryczne?**

Tak moÅ¼na wykorzystaÄ‡ zmienne kategoryczne, ale konieczne jest odpowiednie przetworzenie tych zmiennych, aby mogÅ‚y byÄ‡ uÅ¼ywane w algorytmie KNN. Zmienne kategoryczne, ktÃ³re nie sÄ… numeryczne, muszÄ… byÄ‡ przeksztaÅ‚cone na format numeryczny, aby mogÅ‚y byÄ‡ uÅ¼ywane do obliczania odlegÅ‚oÅ›ci miÄ™dzy punktami danych. MoÅ¼na to zrobiÄ‡ np za pomocÄ…  kodowania one-hot (dummy variables) ktÃ³re przeksztaÅ‚ca zmienne kategoryczne w zmienne binarne. Po przeksztaÅ‚ceniu zmiennych kategorycznych na format numeryczny, moÅ¼na je wykorzystaÄ‡ w algorytmie KNN tak samo, jak zmienne numeryczne. Obliczenia odlegÅ‚oÅ›ci miÄ™dzy punktami danych uwzglÄ™dniÄ… teraz rÃ³wnieÅ¼ zmienne kategoryczne. JednakÅ¼e, warto zaznaczyÄ‡, Å¼e przy uÅ¼yciu kodowania one-hot lub innych technik, wprowadza siÄ™ dodatkowe wymiary do przestrzeni cech, co moÅ¼e prowadziÄ‡ do zwiÄ™kszenia wymiarowoÅ›ci danych i wpÅ‚ynÄ…Ä‡ na zÅ‚oÅ¼onoÅ›Ä‡ obliczeniowÄ….

**8. Jakie sÄ… zalety i wady tej metody?**

**Zalety metody KNN:**

* Prostota implementacji: KNN jest stosunkowo prostym algorytmem, ktÃ³ry jest Å‚atwy do zrozumienia i zaimplementowania. 

* Brak zaÅ‚oÅ¼eÅ„ o rozkÅ‚adzie danych: KNN nie zakÅ‚ada Å¼adnego konkretnego rozkÅ‚adu danych ani liniowej zaleÅ¼noÅ›ci miÄ™dzy zmiennymi, co oznacza, Å¼e moÅ¼e byÄ‡ uÅ¼ywany w rÃ³Å¼norodnych rodzajach danych.

* Dostosowywanie siÄ™ do zmieniajÄ…cych siÄ™ danych: KNN moÅ¼na Å‚atwo dostosowaÄ‡ do zmieniajÄ…cych siÄ™ danych, poniewaÅ¼ nie wymaga ponownego trenowania caÅ‚ego modelu. MoÅ¼na po prostu przeliczyÄ‡ odlegÅ‚oÅ›ci miÄ™dzy nowymi danymi a danymi treningowymi.

**Wady metody KNN:**

* DuÅ¼a zÅ‚oÅ¼onoÅ›Ä‡ obliczeniowa: KNN moÅ¼e byÄ‡ bardzo kosztowny obliczeniowo, zwÅ‚aszcza w przypadku duÅ¼ych zbiorÃ³w danych, poniewaÅ¼ wymaga obliczenia odlegÅ‚oÅ›ci miÄ™dzy wszystkimi punktami danych.

* CzuÅ‚oÅ›Ä‡ na wymiarowoÅ›Ä‡ danych: W miarÄ™ zwiÄ™kszania liczby cech (wymiarÃ³w) danych, algorytm staje siÄ™ mniej efektywny i moÅ¼e dojÅ›Ä‡ do problemu przekleÅ„stwa wymiarowoÅ›ci (curse of dimensionality), co moÅ¼e pogorszyÄ‡ wydajnoÅ›Ä‡ modelu.

* WpÅ‚yw szumu i outlierÃ³w: KNN jest wraÅ¼liwy na obserwacje odstajÄ…ce (outliers) i szum w danych, poniewaÅ¼ opiera siÄ™ na odlegÅ‚oÅ›ciach. Jedna lub kilka odstajÄ…cych obserwacji moÅ¼e wpÅ‚ynÄ…Ä‡ na wyniki.

* WpÅ‚yw wyboru parametru k: WybÃ³r odpowiedniej wartoÅ›ci parametru "k" (liczba sÄ…siadÃ³w) jest kluczowy, i nie istnieje jedna "najlepsza" wartoÅ›Ä‡ "k" dla wszystkich problemÃ³w. NiewÅ‚aÅ›ciwy wybÃ³r "k" moÅ¼e prowadziÄ‡ do nadmiernego dopasowania lub niedopasowania.

* Kategoryczne i brakujÄ…ce dane: ObsÅ‚uga zmiennych kategorycznych i brakujÄ…cych danych w KNN moÅ¼e byÄ‡ trudniejsza i wymaga specjalnych technik przeksztaÅ‚cania i imputacji danych.



## **Zadanie 3. Metoda KKNN** 

**1. Co odrÃ³Å¼nia metodÄ™ KKNN od metody KNN?**

Metoda KKNN, w odrÃ³Å¼nieniu od tradycyjnej metody KNN, zmienia podejÅ›cie do uwzglÄ™dniania sÄ…siadÃ³w przy dokonywaniu prognoz. W KNN wszyscy sÄ…siedzi majÄ… jednakowÄ… wagÄ™ niezaleÅ¼nie od odlegÅ‚oÅ›ci, co oznacza, Å¼e kaÅ¼dy ma rÃ³wny wpÅ‚yw na wynik. Natomiast w KKNN kaÅ¼demu z k najbliÅ¼szych sÄ…siadÃ³w moÅ¼na przypisaÄ‡ indywidualnÄ… wagÄ™, ktÃ³ra moÅ¼e byÄ‡ dostosowana na podstawie rÃ³Å¼nych czynnikÃ³w, takich jak odlegÅ‚oÅ›Ä‡ czy jakoÅ›Ä‡ sÄ…siada. SÄ…siedzi z wyÅ¼szymi wagami majÄ… wiÄ™kszy wpÅ‚yw na prognozÄ™, a ci z niÅ¼szymi - mniejszy lub Å¼aden wpÅ‚yw.

**2. Czy w metodzie tej wystÄ™pujÄ… ograniczenia dotyczÄ…ce wyboru wartoÅ›ci k?**

Ograniczenia dotyczÄ…ce wyboru wartoÅ›ci k w metodzie KKNN i tradycyjnej metodzie KNN) sÄ… podobne w pewnym sensie, ale istniejÄ… rÃ³wnieÅ¼ pewne rÃ³Å¼nice zwiÄ…zane z uwzglÄ™dnianiem wag sÄ…siadÃ³w w KKNN - wartoÅ›Ä‡ k nadal okreÅ›la liczbÄ™ sÄ…siadÃ³w branych pod uwagÄ™, ale kaÅ¼demu sÄ…siadowi przypisuje siÄ™ indywidualnÄ… wagÄ™, co oznacza, Å¼e rÃ³Å¼ni sÄ…siedzi mogÄ… mieÄ‡ rÃ³Å¼ny wpÅ‚yw na wynik prognozy. Dla rÃ³Å¼nych zbiorÃ³w danych i problemÃ³w moÅ¼e istnieÄ‡ rÃ³Å¼na optymalna wartoÅ›Ä‡ k, dlatego wartoÅ›ci te naleÅ¼y dostosowaÄ‡ do konkretnego przypadku.

**3. Czy wielkoÅ›Ä‡ zbioru danych ma znaczenie w przypadku tej metody? SprawdziÄ‡, czy liczba obserwacji wpÅ‚ywa na uzyskiwane wyniki.**

W metodzie KKNN, zbyt maÅ‚a iloÅ›Ä‡ danych moÅ¼e wpÅ‚ynÄ…Ä‡ na ryzyko overfittingu,poniewaÅ¼ model moÅ¼e byÄ‡ zbyt dostosowany do maÅ‚ej iloÅ›ci danych. W przypadku bardzo maÅ‚ych zbiorach danych, poniewaÅ¼ wyniki mogÄ… byÄ‡ niestabilne i trudne do uogÃ³lnienia. Optymalna iloÅ›Ä‡ danych zaleÅ¼y od konkretnej sytuacji i problemu, ktÃ³ry prÃ³bujemy rozwiÄ…zaÄ‡. W naszym przypadku zastosowanie wiÄ™kszej liczby obserwacji (mniejszej niÅ¼ pozbalansowaniu) daÅ‚o lepsze wyniki.

```{r}
trControl <- trainControl(method = "repeatedcv", 
                          number = 10,  
                          repeats = 1,  
                          classProbs = TRUE,
                          summaryFunction = twoClassSummary)  
# KKNN
fit <- train(Stroke ~ ., 
             data = train_set,
             method = "kknn",
             tuneLength = 5,
             metric     = "ROC", 
             trControl = trControl,
             preProc = c("center", "scale"))


fit
plot(fit)
varImp(fit)

pred <- predict(fit, newdata = test_set )
confusionMatrix(pred, test_set$Stroke, positive = 'tak' )
```


## **Zadanie 4. Regresja logistyczna** 

**1. Jakie sÄ… zaÅ‚oÅ¼enie regresji logistycznej?**

**Linia podziaÅ‚u:** Regresja logistyczna zakÅ‚ada, Å¼e istnieje liniowa granica decyzyjna, ktÃ³ra oddziela dwie klasy w przestrzeni cech. Modele regresji logistycznej starajÄ… siÄ™ znaleÅºÄ‡ liniowy podziaÅ‚ miÄ™dzy danymi wejÅ›ciowymi, ktÃ³ry najlepiej oddziela dwie klasy. W praktyce moÅ¼e to oznaczaÄ‡, Å¼e dane moÅ¼na odseparowaÄ‡ za pomocÄ… pÅ‚aszczyzny lub hiperpÅ‚aszczyzny w zaleÅ¼noÅ›ci od liczby cech.

**NiezaleÅ¼noÅ›Ä‡ cech:** Regresja logistyczna zakÅ‚ada, Å¼e cechy wejÅ›ciowe sÄ… niezaleÅ¼ne od siebie. WpÅ‚yw kaÅ¼dej cechy na wynik klasyfikacji jest niezaleÅ¼ny od innych cech. To zaÅ‚oÅ¼enie moÅ¼e byÄ‡ problematyczne w przypadku, gdy cechy sÄ… skorelowane, dlatego warto przeprowadziÄ‡ analizÄ™ cech i ewentualnie zastosowaÄ‡ techniki redukcji wymiaru lub selekcji cech.

**LiniowoÅ›Ä‡ logitu:** W regresji logistycznej stosuje siÄ™ logit jako funkcjÄ™ odnoÅ›nie do cech wejÅ›ciowych. Logit to logarytm szansy (odsetka) przynaleÅ¼noÅ›ci do jednej z klas. ZaÅ‚oÅ¼enie to mÃ³wi, Å¼e logit jest funkcjÄ… liniowÄ… cech wejÅ›ciowych. Oznacza to, Å¼e regresja logistyczna zakÅ‚ada liniowÄ… zaleÅ¼noÅ›Ä‡ miÄ™dzy cechami a logitem.

**Brak wielomianowych interakcji:** Regresja logistyczna zakÅ‚ada, Å¼e nie ma znaczÄ…cych wielomianowych interakcji miÄ™dzy cechami. JeÅ›li takie interakcje istniejÄ…, to moÅ¼e byÄ‡ konieczne rozwaÅ¼enie bardziej zaawansowanych modeli lub przeksztaÅ‚ceÅ„ cech.

**2. Jak metoda ta radzi sobie ze zmiennymi kategorycznymi?**

Zmienne kategoryczne w regresji logistycznej muszÄ… byÄ‡ przeksztaÅ‚cone w sposÃ³b umoÅ¼liwiajÄ…cy ich uÅ¼ycie jako predyktorÃ³w w modelu. NajczÄ™Å›ciej stosuje siÄ™ kodowanie kategoryczne, ktÃ³re przeksztaÅ‚ca zmienne kategoryczne na zmienne binarne lub uÅ¼ywa ich jako zmiennej porzÄ…dkowej.

**3. Czy w przypadku regresji logistycznej konieczna jest standaryzacja danych? ZastosowaÄ‡ tÄ™ metodÄ™ na danych bez standaryzacji i ze standaryzacjÄ…. PorÃ³wnaÄ‡ uzyskane wyniki.**

**bez standaryzacji**
```{r}
#regresja logisyczna 
formula <- Stroke~.
model <- glm(formula , data = train_set, family = binomial)

#predykcja na zbiorze testowym
predictions <- predict(model, test_set, type = 'response')

#zamiana prawdopodobienstwa na 0 i 1 
predicted_classes <- ifelse(predictions >= 0.5, 'tak' , 'nie')
predicted_classes <- as.factor(predicted_classes)
confusionMatrix(predicted_classes, test_set$Stroke, positive = 'tak' )
```

**ze standaryzacja**
```{r}
# regresja logisyczna 
formula <- Stroke~.
model <- glm(formula , data = train_set2, family = binomial)

# predykcja na zbiorze testowym
predictions <- predict(model, test_set2, type = 'response')

# zamiana prawdopodobienstwa na 0 i 1 
predicted_classes <- ifelse(predictions >= 0.5, 'tak' , 'nie')
predicted_classes <- as.factor(predicted_classes)
confusionMatrix(predicted_classes, test_set2$Stroke, positive = 'tak' )
```

W obu przypadkach otrzymano takie same wyniki.


**4. Czy wartoÅ›ci odstajÄ…ce majÄ… wpÅ‚yw na uzyskiwane tÄ… metodÄ… wyniki? ZweryfikowaÄ‡ to budujÄ…c modele w oparciu o rÃ³Å¼ne zestawy danych wejÅ›ciowych (z wartoÅ›ciami i bez wartoÅ›ci odstajÄ…cych).** 

```{r}
# Funkcja do wykrywania wartoÅ›ci odstajÄ…cych na podstawie IQR
detect_outliers_iqr <- function(series) {
  Q1 <- quantile(series, 0.25, na.rm = TRUE)
  Q3 <- quantile(series, 0.75, na.rm = TRUE)
  IQR <- Q3 - Q1
  lower_bound <- Q1 - 1.5 * IQR
  upper_bound <- Q3 + 1.5 * IQR
  outliers <- (series < lower_bound) | (series > upper_bound)
  return(outliers)
}

# Funkcja do wykrywania wartoÅ›ci odstajÄ…cych na podstawie odchylenia standardowego
detect_outliers_std <- function(series, n_std = 3) {
  mean_val <- mean(series, na.rm = TRUE)
  std_val <- sd(series, na.rm = TRUE)
  lower_bound <- mean_val - n_std * std_val
  upper_bound <- mean_val + n_std * std_val
  outliers <- (series < lower_bound) | (series > upper_bound)
  return(outliers)
}

remove_outliers <- function(data, method = "IQR") {
  if (method == "IQR") {
    outliers <- apply(data, 2, detect_outliers_iqr)
  } else if (method == "STD") {
    outliers <- apply(data, 2, detect_outliers_std)
  } else {
    stop("Nieznana metoda. WprowadÅº 'IQR' lub 'STD'.")
  }
  
# Usuwanie obserwacji odstajÄ…cych ze zbioru danych
  data_cleaned <- data
  data_cleaned[outliers] <- NA
  data_cleaned <- na.omit(data_cleaned)
  
  return(data_cleaned)
}

# Wykrywanie obserwacji odstajÄ…cych i usuwanie ich na podstawie wybranej metody
kolumny_do_usuniecia_odstajacych <- dane1[, c(2, 6, 7)]

# Usuwanie obserwacji odstajÄ…cych tylko z wybranych kolumn
kolumny_po_usunieciu_iqr <- remove_outliers(kolumny_do_usuniecia_odstajacych, method = "IQR")

dane_po_usunieciu_iqr <- dane1[rownames(kolumny_po_usunieciu_iqr), ]
table(dane_po_usunieciu_iqr$Stroke)

# bez standaryzacji 
set.seed(123)
ind <- sample(2, nrow(dane_po_usunieciu_iqr), replace = TRUE, prob = c(0.7, 0.3))
train_set3 <- dane_po_usunieciu_iqr[ind==1,]
test_set3 <- dane_po_usunieciu_iqr[ind==2,]



# regresja logisyczna 
formula <- Stroke~.
model <- glm(formula , data = train_set3, family = binomial)

# predykcja na zbiorze testowym
predictions <- predict(model, test_set3, type = 'response')

# zamiana prawdopodobienstwa na 0 i 1 
predicted_classes <- ifelse(predictions >= 0.5, 'tak' , 'nie')
predicted_classes <- as.factor(predicted_classes)
confusionMatrix(predicted_classes, test_set3$Stroke, positive = 'tak' )
```

W naszym przypadku usuniÄ™cie wartoÅ›ci odstajÄ…cych polepszyÅ‚a wyniki. Otrzymana zostaÅ‚a dobra dokÅ‚adnoÅ›Ä‡, lecz nadal predykcja doÅ›Ä‡ bÅ‚Ä™dnie przewiduje zmiennÄ… Stroke("Nie").

**5. W jaki sposÃ³b naleÅ¼y interpretowaÄ‡ wyniki (wartoÅ›ci parametrÃ³w) uzyskiwane w regresji logistycznej? ZinterpretowaÄ‡ wartoÅ›ci parametrÃ³w uzyskane podczas budowy modelu regresji logistycznej.**

Interpretacja wynikÃ³w uzyskiwanych w regresji logistycznej polega na zrozumieniu, jak zmienne niezaleÅ¼ne wpÅ‚ywajÄ… na prawdopodobieÅ„stwo przynaleÅ¼noÅ›ci do danej klasy w problemie klasyfikacji binarnej. Parametr Specifity wynosi 0.97087, co oznacza, Å¼e model jest w stanie poprawnie zidentyfikowaÄ‡ 97,09% rzeczywistych negatywnych przypadkÃ³w. Model wykazuje wysokÄ… zdolnoÅ›Ä‡ do identyfikacji negatywnych przypadkÃ³w.CzuÅ‚oÅ›Ä‡ wynosi 0.26190, co oznacza, Å¼e model jest w stanie poprawnie zidentyfikowaÄ‡ tylko 26,19% rzeczywistych pozytywnych przypadkÃ³w. To oznacza, Å¼e model ma trudnoÅ›ci z wykrywaniem pozytywnych przypadkÃ³w. DokÅ‚adnoÅ›Ä‡ wynosi 0.8508, co oznacza, Å¼e model jest w stanie poprawnie sklasyfikowaÄ‡ 85,08% obserwacji.

## **Zadanie 5. Krzywa ROC i wartoÅ›Ä‡ AUC** 

**1. Co to jest prÃ³g odciÄ™cia?**

PrÃ³g odciÄ™cia w kontekÅ›cie analizy danych i uczenia maszynowego to ustalona wartoÅ›Ä‡ lub punkt graniczny, ktÃ³ry jest uÅ¼ywany do podjÄ™cia decyzji binarnej lub wieloklasowej na podstawie wynikÃ³w modelu lub algorytmu. PrÃ³g odciÄ™cia jest stosowany gÅ‚Ã³wnie w zastosowaniach klasyfikacji, gdzie celem jest przypisanie obiektÃ³w do okreÅ›lonych kategorii lub klas.

Kiedy model generuje wyniki numeryczne, takie jak prawdopodobieÅ„stwa przynaleÅ¼noÅ›ci do rÃ³Å¼nych klas, prÃ³g odciÄ™cia pomaga dokonaÄ‡ ostatecznej klasyfikacji, okreÅ›lajÄ…c, ktÃ³re wyniki zostanÄ… zaklasyfikowane do danej klasy, a ktÃ³re do innej. WartoÅ›Ä‡ progowa jest wykorzystywana jako granica decyzyjna.

**2. Co to jest krzywa ROC i wartoÅ›Ä‡ AUC? W jaki sposÃ³b sÄ… one tworzone/obliczane?**

Krzywa ROC jest tworzona przez zmienianie wartoÅ›ci progowej (threshold) modelu klasyfikacyjnego i obliczanie TPR i FPR dla kaÅ¼dej wartoÅ›ci progowej. NastÄ™pnie te wyniki sÄ… punktami na wykresie, a krzywa jest krzywÄ… Å‚Ä…czÄ…cÄ… te punkty. Idealny model miaÅ‚by krzywÄ… ROC przechodzÄ…cÄ… przez punkt (0,1), co oznaczaÅ‚oby, Å¼e ma 100% czuÅ‚oÅ›ci (TPR) i 0% bÅ‚Ä™du faÅ‚szywie pozytywnego (FPR).

AUC to obszar pod krzywa ROC, sÅ‚uÅ¼y do oceny poprawnoÅ›ci klasyfikatora. Przyjmuje wartoÅ›ci z zakresu [0,1], gdzie 0.5 oznacza model losowy, a 1 model idealny

Obliczanie AUC moÅ¼na wykonaÄ‡ za pomocÄ… rÃ³Å¼nych metod, w tym przy uÅ¼yciu caÅ‚ki numerycznej pod krzywÄ… ROC lub za pomocÄ… odpowiednich bibliotek i narzÄ™dzi do analizy danych i uczenia maszynowego, takich jak scikit-learn w jÄ™zyku Python.

**3. ZaprezentowaÄ‡ krzywÄ… ROC dla modeli: KNN i regresji logistycznej. PorÃ³wnaÄ‡ je ze sobÄ….**
```{r}
# KNN
trControl <- trainControl(method = "repeatedcv", 
                          number = 10,  
                          repeats = 3, 
                          classProbs = TRUE,
                          summaryFunction = twoClassSummary)  
set.seed(1234)
fit <- train(Stroke ~ ., 
             data = train_set,
             tuneGrid   = expand.grid(k = 1:20),
             method = "knn",
             tuneLength = 20,
             metric     = "ROC", 
             trControl = trControl,
             preProc = c("center", "scale")) 

pred <- predict(fit, newdata = test_set )
confusionMatrix(pred, test_set$Stroke, positive = 'tak' )

# Wykres ROC i AUC 
pred <- predict(fit, newdata = test_set, type = 'prob')[,2]
roc_obj <- roc(test_set$Stroke, pred)
auc <- round(auc(test_set$Stroke, pred),4)

# Rysowanie krzywej ROC
ggroc(roc_obj,colour = 'steelblue',size=2,legacy.axes = TRUE) +
  geom_abline(linetype = "dashed") +
  theme(panel.border = element_rect(color = 'black',fill = NA,size = 1),
        panel.background = element_rect(fill='gray95'),
        plot.background = element_rect(color = 'black', size = 1) 
  )+
  ggtitle(paste0('Krzywa ROC ', '(AUC = ', auc, ')')) +
  labs(x = "1 - SwoistoÅ›Ä‡",
       y = "SwoistoÅ›Ä‡")


# regresja logisyczna 
formula <- Stroke~.
model <- glm(formula , data = train_set, family = binomial)

# predykcj na zbiorze testowym
predictions <- predict(model, test_set, type = 'response')

# PrzeksztaÅ‚cenie wynikow na formÄ™ binarnÄ… (0 lub 1)
predicted_classes <- ifelse(predictions >= 0.5, 'tak' , 'nie')
predicted_classes <- as.factor(predicted_classes)
confusionMatrix(predicted_classes, test_set$Stroke, positive = 'tak' )

# Wykres ROC i AUC 
roc_obj <- roc(test_set$Stroke, predictions)
auc <- round(auc(test_set$Stroke, predictions),4)

# Rysowanie krzywej ROC
ggroc(roc_obj,colour = 'steelblue',size=2,legacy.axes = TRUE) +
  geom_abline(linetype = "dashed") +
  theme(panel.border = element_rect(color = 'black',fill = NA,size = 1),
        panel.background = element_rect(fill='gray95'),
        plot.background = element_rect(color = 'black', size = 1) 
  )+
  ggtitle(paste0('Krzywa ROC ', '(AUC = ', auc, ')')) +
  labs(x = "1 - SwoistoÅ›Ä‡",
       y = "SwoistoÅ›Ä‡")
```

Krzywe ROC dla KNN i regresji logistycznej w naszym przypadku majÄ… podobny wyglÄ…d,lecz ich interpretacja rÃ³zni siÄ™ od siebie. WartoÅ›Ä‡ AUC (Pole pod krzywÄ…) dla KNN wyniosÅ‚a 0,727 (przeciÄ™tnÄ… zdolnoÅ›Ä‡ modelu), dla regresji byÅ‚o to 0,8305 (dobra zdolnoÅ›Ä‡ modelu). PoÅ‚oÅ¼enie krzywej mÃ³wi, Å¼e im bliÅ¼ej jest gÃ³rnego punktu wykresu (punkt (0,1)) to lepsza jest zdolnoÅ›Ä‡ modelu do rozrÃ³Å¼niania klas. W naszym przypadku krzywa jest bliÅ¼ej tego punktu dla regresji.